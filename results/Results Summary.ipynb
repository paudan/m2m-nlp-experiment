{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from performance import calculate_extraction_performance, single_verb, calculate_ner_performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb phrase/noun phrase extraction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyVerbRequired</th>\n",
       "      <td>0.701674</td>\n",
       "      <td>0.792491</td>\n",
       "      <td>0.71791</td>\n",
       "      <td>0.817859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreVerbRequired</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.877435</td>\n",
       "      <td>0.825705</td>\n",
       "      <td>0.893503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccuracyNounRequired</th>\n",
       "      <td>0.847793</td>\n",
       "      <td>0.94622</td>\n",
       "      <td>0.859462</td>\n",
       "      <td>0.974632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNounRequired</th>\n",
       "      <td>0.916574</td>\n",
       "      <td>0.972046</td>\n",
       "      <td>0.923332</td>\n",
       "      <td>0.986972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputNoun</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.831858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputNoun</th>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.681034</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputNoun</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.70852</td>\n",
       "      <td>0.629108</td>\n",
       "      <td>0.820961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Nouns</th>\n",
       "      <td>0.640052</td>\n",
       "      <td>0.690899</td>\n",
       "      <td>0.671103</td>\n",
       "      <td>0.760492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Nouns</th>\n",
       "      <td>0.548248</td>\n",
       "      <td>0.662534</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.74717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Nouns</th>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>0.625046</td>\n",
       "      <td>0.753772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Verbs</th>\n",
       "      <td>0.52801</td>\n",
       "      <td>0.580424</td>\n",
       "      <td>0.540558</td>\n",
       "      <td>0.623391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Verbs</th>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.577358</td>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.621563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Verbs</th>\n",
       "      <td>0.520504</td>\n",
       "      <td>0.578887</td>\n",
       "      <td>0.526528</td>\n",
       "      <td>0.622476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            corenlp     flair     spacy    stanza\n",
       "AccuracyVerbRequired       0.701674  0.792491   0.71791  0.817859\n",
       "F1ScoreVerbRequired          0.8125  0.877435  0.825705  0.893503\n",
       "AccuracyNounRequired       0.847793   0.94622  0.859462  0.974632\n",
       "F1ScoreNounRequired        0.916574  0.972046  0.923332  0.986972\n",
       "PrecisionOutputNoun        0.619048  0.738318  0.690722  0.831858\n",
       "RecallOutputNoun           0.560345  0.681034  0.577586  0.810345\n",
       "F1ScoreOutputNoun          0.588235   0.70852  0.629108  0.820961\n",
       "PrecisionOutputBoth_Nouns  0.640052  0.690899  0.671103  0.760492\n",
       "RecallOutputBoth_Nouns     0.548248  0.662534  0.584906   0.74717\n",
       "F1ScoreOutputBoth_Nouns    0.590604  0.676419  0.625046  0.753772\n",
       "PrecisionOutputBoth_Verbs   0.52801  0.580424  0.540558  0.623391\n",
       "RecallOutputBoth_Verbs     0.513208  0.577358  0.513208  0.621563\n",
       "F1ScoreOutputBoth_Verbs    0.520504  0.578887  0.526528  0.622476"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(os.path.join('..', 'datasets', 'activity_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-phrases.csv', 'flair-phrases.csv', 'spacy-phrases.csv', 'stanza-phrases.csv']\n",
    "results = pd.DataFrame([calculate_extraction_performance(file, original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyNEFound</th>\n",
       "      <td>0.613992</td>\n",
       "      <td>0.811155</td>\n",
       "      <td>0.799902</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEFound</th>\n",
       "      <td>0.323907</td>\n",
       "      <td>0.603696</td>\n",
       "      <td>0.531501</td>\n",
       "      <td>0.763243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEEntry</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.932011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEEntry</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.731111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEEntry</th>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.519062</td>\n",
       "      <td>0.819427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEType</th>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.87415</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>0.934844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEType</th>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.735556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEType</th>\n",
       "      <td>0.346641</td>\n",
       "      <td>0.69086</td>\n",
       "      <td>0.569839</td>\n",
       "      <td>0.823312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   corenlp     flair     spacy    stanza\n",
       "AccuracyNEFound   0.613992  0.811155  0.799902  0.892857\n",
       "F1ScoreNEFound    0.323907  0.603696  0.531501  0.763243\n",
       "PrecisionNEEntry  0.619048  0.734694  0.762931  0.932011\n",
       "RecallNEEntry         0.26      0.48  0.393333  0.731111\n",
       "F1ScoreNEEntry    0.366197  0.580645  0.519062  0.819427\n",
       "PrecisionNEType   0.582888   0.87415  0.831897  0.934844\n",
       "RecallNEType      0.246667  0.571111  0.433333  0.735556\n",
       "F1ScoreNEType     0.346641   0.69086  0.569839  0.823312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_original = pd.read_csv(os.path.join('..', 'datasets', 'ner_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-ner.csv', 'flair-ner.csv', 'spacy-ner.csv', 'stanza-ner.csv']\n",
    "results = pd.DataFrame([calculate_ner_performance(file, ner_original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
