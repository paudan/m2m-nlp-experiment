{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from performance import calculate_extraction_performance, single_verb, calculate_ner_performance\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb phrase/noun phrase extraction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyVerbRequired</th>\n",
       "      <td>0.701674</td>\n",
       "      <td>0.792491</td>\n",
       "      <td>0.757484</td>\n",
       "      <td>0.817859</td>\n",
       "      <td>0.824455</td>\n",
       "      <td>0.941147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreVerbRequired</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.877435</td>\n",
       "      <td>0.853733</td>\n",
       "      <td>0.893503</td>\n",
       "      <td>0.898115</td>\n",
       "      <td>0.969681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccuracyNounRequired</th>\n",
       "      <td>0.847793</td>\n",
       "      <td>0.94622</td>\n",
       "      <td>0.980213</td>\n",
       "      <td>0.974632</td>\n",
       "      <td>0.983257</td>\n",
       "      <td>0.985287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNounRequired</th>\n",
       "      <td>0.916574</td>\n",
       "      <td>0.972046</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.986972</td>\n",
       "      <td>0.991471</td>\n",
       "      <td>0.992505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputNoun</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.0204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputNoun</th>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.681034</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.0172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputNoun</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.70852</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.820961</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.0186916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Nouns</th>\n",
       "      <td>0.640052</td>\n",
       "      <td>0.690899</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.760492</td>\n",
       "      <td>0.735828</td>\n",
       "      <td>0.713584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Nouns</th>\n",
       "      <td>0.548248</td>\n",
       "      <td>0.662534</td>\n",
       "      <td>0.678706</td>\n",
       "      <td>0.74717</td>\n",
       "      <td>0.731536</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Nouns</th>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>0.681144</td>\n",
       "      <td>0.753772</td>\n",
       "      <td>0.733676</td>\n",
       "      <td>0.715279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Verbs</th>\n",
       "      <td>0.52801</td>\n",
       "      <td>0.580424</td>\n",
       "      <td>0.110436</td>\n",
       "      <td>0.623391</td>\n",
       "      <td>0.121629</td>\n",
       "      <td>0.166394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Verbs</th>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.577358</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.621563</td>\n",
       "      <td>0.120216</td>\n",
       "      <td>0.168194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Verbs</th>\n",
       "      <td>0.520504</td>\n",
       "      <td>0.578887</td>\n",
       "      <td>0.109933</td>\n",
       "      <td>0.622476</td>\n",
       "      <td>0.120918</td>\n",
       "      <td>0.167289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            corenlp     flair     spacy    stanza      bert  \\\n",
       "AccuracyVerbRequired       0.701674  0.792491  0.757484  0.817859  0.824455   \n",
       "F1ScoreVerbRequired          0.8125  0.877435  0.853733  0.893503  0.898115   \n",
       "AccuracyNounRequired       0.847793   0.94622  0.980213  0.974632  0.983257   \n",
       "F1ScoreNounRequired        0.916574  0.972046  0.989899  0.986972  0.991471   \n",
       "PrecisionOutputNoun        0.619048  0.738318  0.767857  0.831858  0.780702   \n",
       "RecallOutputNoun           0.560345  0.681034  0.741379  0.810345  0.767241   \n",
       "F1ScoreOutputNoun          0.588235   0.70852  0.754386  0.820961  0.773913   \n",
       "PrecisionOutputBoth_Nouns  0.640052  0.690899    0.6836  0.760492  0.735828   \n",
       "RecallOutputBoth_Nouns     0.548248  0.662534  0.678706   0.74717  0.731536   \n",
       "F1ScoreOutputBoth_Nouns    0.590604  0.676419  0.681144  0.753772  0.733676   \n",
       "PrecisionOutputBoth_Verbs   0.52801  0.580424  0.110436  0.623391  0.121629   \n",
       "RecallOutputBoth_Verbs     0.513208  0.577358  0.109434  0.621563  0.120216   \n",
       "F1ScoreOutputBoth_Verbs    0.520504  0.578887  0.109933  0.622476  0.120918   \n",
       "\n",
       "                              manual  \n",
       "AccuracyVerbRequired        0.941147  \n",
       "F1ScoreVerbRequired         0.969681  \n",
       "AccuracyNounRequired        0.985287  \n",
       "F1ScoreNounRequired         0.992505  \n",
       "PrecisionOutputNoun        0.0204082  \n",
       "RecallOutputNoun           0.0172414  \n",
       "F1ScoreOutputNoun          0.0186916  \n",
       "PrecisionOutputBoth_Nouns   0.713584  \n",
       "RecallOutputBoth_Nouns      0.716981  \n",
       "F1ScoreOutputBoth_Nouns     0.715279  \n",
       "PrecisionOutputBoth_Verbs   0.166394  \n",
       "RecallOutputBoth_Verbs      0.168194  \n",
       "F1ScoreOutputBoth_Verbs     0.167289  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(os.path.join('..', 'datasets', 'activity_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-phrases.csv', 'flair-phrases.csv', 'spacy-phrases.csv', 'stanza-phrases.csv', 'bert-phrases.csv', 'manual-phrases.csv']\n",
    "results = pd.DataFrame([calculate_extraction_performance(file, original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyNEFound</th>\n",
       "      <td>0.819472</td>\n",
       "      <td>0.815558</td>\n",
       "      <td>0.815558</td>\n",
       "      <td>0.920744</td>\n",
       "      <td>0.732877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEFound</th>\n",
       "      <td>0.436641</td>\n",
       "      <td>0.605236</td>\n",
       "      <td>0.572077</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.526863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEEntry</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.381579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEEntry</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.428889</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.257778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEEntry</th>\n",
       "      <td>0.354132</td>\n",
       "      <td>0.581867</td>\n",
       "      <td>0.549858</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEType</th>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.889273</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.754098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEType</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.731111</td>\n",
       "      <td>0.513333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEType</th>\n",
       "      <td>0.421377</td>\n",
       "      <td>0.695535</td>\n",
       "      <td>0.644667</td>\n",
       "      <td>0.823467</td>\n",
       "      <td>0.610848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   corenlp     flair     spacy    stanza      bert\n",
       "AccuracyNEFound   0.819472  0.815558  0.815558  0.920744  0.732877\n",
       "F1ScoreNEFound    0.436641  0.605236  0.572077  0.811189  0.526863\n",
       "PrecisionNEEntry  0.734266  0.743945  0.765873  0.939655  0.381579\n",
       "RecallNEEntry     0.233333  0.477778  0.428889  0.726667  0.257778\n",
       "F1ScoreNEEntry    0.354132  0.581867  0.549858  0.819549  0.307692\n",
       "PrecisionNEType    0.87234  0.889273  0.892857  0.942529  0.754098\n",
       "RecallNEType      0.277778  0.571111  0.504444  0.731111  0.513333\n",
       "F1ScoreNEType     0.421377  0.695535  0.644667  0.823467  0.610848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_original = pd.read_csv(os.path.join('..', 'datasets', 'ner_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-ner.csv', 'flair-ner.csv', 'spacy-ner.csv', 'stanza-ner.csv', 'bert-ner.csv']\n",
    "results = pd.DataFrame([calculate_ner_performance(file, ner_original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
