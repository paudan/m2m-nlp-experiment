{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from performance import calculate_extraction_performance, single_verb, calculate_ner_performance\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb phrase/noun phrase extraction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>allen</th>\n",
       "      <th>custom</th>\n",
       "      <th>custom2</th>\n",
       "      <th>manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyVerbRequired</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreVerbRequired</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccuracyNounRequired</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNounRequired</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputNoun</th>\n",
       "      <td>0.619</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputNoun</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputNoun</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Nouns</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Nouns</th>\n",
       "      <td>0.548</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Nouns</th>\n",
       "      <td>0.591</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Verbs</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Verbs</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Verbs</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          corenlp flair spacy stanza  bert allen custom  \\\n",
       "AccuracyVerbRequired        0.702 0.792 0.757  0.818 0.824 0.656  0.799   \n",
       "F1ScoreVerbRequired         0.812 0.877 0.854  0.894 0.898 0.780  0.882   \n",
       "AccuracyNounRequired        0.848 0.946 0.980  0.975 0.983 0.973  0.917   \n",
       "F1ScoreNounRequired         0.917 0.972 0.990  0.987 0.991 0.986  0.956   \n",
       "PrecisionOutputNoun         0.619 0.738 0.768  0.832 0.781 0.736  0.642   \n",
       "RecallOutputNoun            0.560 0.681 0.741  0.810 0.767 0.698  0.603   \n",
       "F1ScoreOutputNoun           0.588 0.709 0.754  0.821 0.774 0.717  0.622   \n",
       "PrecisionOutputBoth_Nouns   0.640 0.691 0.684  0.760 0.736 0.552  0.690   \n",
       "RecallOutputBoth_Nouns      0.548 0.663 0.679  0.747 0.732 0.547  0.638   \n",
       "F1ScoreOutputBoth_Nouns     0.591 0.676 0.681  0.754 0.734 0.550  0.663   \n",
       "PrecisionOutputBoth_Verbs   0.528 0.580 0.110  0.623 0.122 0.087  0.123   \n",
       "RecallOutputBoth_Verbs      0.513 0.577 0.109  0.622 0.120 0.087  0.117   \n",
       "F1ScoreOutputBoth_Verbs     0.521 0.579 0.110  0.622 0.121 0.087  0.120   \n",
       "\n",
       "                          custom2 manual  \n",
       "AccuracyVerbRequired        0.842  0.941  \n",
       "F1ScoreVerbRequired         0.909  0.970  \n",
       "AccuracyNounRequired        0.957  0.985  \n",
       "F1ScoreNounRequired         0.978  0.993  \n",
       "PrecisionOutputNoun         0.727  0.020  \n",
       "RecallOutputNoun            0.690  0.017  \n",
       "F1ScoreOutputNoun           0.708  0.019  \n",
       "PrecisionOutputBoth_Nouns   0.745  0.714  \n",
       "RecallOutputBoth_Nouns      0.720  0.717  \n",
       "F1ScoreOutputBoth_Nouns     0.732  0.715  \n",
       "PrecisionOutputBoth_Verbs   0.132  0.166  \n",
       "RecallOutputBoth_Verbs      0.126  0.168  \n",
       "F1ScoreOutputBoth_Verbs     0.129  0.167  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(os.path.join('..', 'datasets', 'activity_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-phrases.csv', 'flair-phrases.csv', 'spacy-phrases.csv', 'stanza-phrases.csv', \n",
    "                'bert-phrases.csv', 'allen-phrases.csv', 'custom-phrases.csv', \n",
    "                'custom2-phrases.csv', 'manual-phrases.csv']\n",
    "results = pd.DataFrame([calculate_extraction_performance(file, original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>allen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyNEFound</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEFound</th>\n",
       "      <td>0.437</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEEntry</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEEntry</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEEntry</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEType</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEType</th>\n",
       "      <td>0.278</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEType</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 corenlp flair spacy stanza  bert allen\n",
       "AccuracyNEFound    0.819 0.816 0.816  0.921 0.733 0.807\n",
       "F1ScoreNEFound     0.437 0.605 0.572  0.811 0.527 0.624\n",
       "PrecisionNEEntry   0.734 0.744 0.766  0.940 0.382 0.756\n",
       "RecallNEEntry      0.233 0.478 0.429  0.727 0.258 0.551\n",
       "F1ScoreNEEntry     0.354 0.582 0.550  0.820 0.308 0.638\n",
       "PrecisionNEType    0.872 0.889 0.893  0.943 0.754 0.890\n",
       "RecallNEType       0.278 0.571 0.504  0.731 0.513 0.653\n",
       "F1ScoreNEType      0.421 0.696 0.645  0.823 0.611 0.754"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_original = pd.read_csv(os.path.join('..', 'datasets', 'ner_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-ner.csv', 'flair-ner.csv', 'spacy-ner.csv', 'stanza-ner.csv', 'bert-ner.csv', 'allen-ner.csv']\n",
    "results = pd.DataFrame([calculate_ner_performance(file, ner_original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].values.tolist()\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
