{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from performance import calculate_extraction_performance, single_verb, calculate_ner_performance\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb phrase/noun phrase extraction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Extractor</th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>allen</th>\n",
       "      <th>custom</th>\n",
       "      <th>custom2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyVerbRequired</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreVerbRequired</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccuracyNounRequired</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNounRequired</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputNoun</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputNoun</th>\n",
       "      <td>0.591</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputNoun</th>\n",
       "      <td>0.628</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Nouns</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Nouns</th>\n",
       "      <td>0.551</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Nouns</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Verbs</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Verbs</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Verbs</th>\n",
       "      <td>0.591</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Extractor                 corenlp flair spacy stanza  bert allen custom  \\\n",
       "AccuracyVerbRequired        0.728 0.817 0.816  0.820 0.857 0.686  0.818   \n",
       "F1ScoreVerbRequired         0.827 0.890 0.890  0.892 0.916 0.797  0.891   \n",
       "AccuracyNounRequired        0.844 0.988 0.983  0.990 0.988 0.980  0.921   \n",
       "F1ScoreNounRequired         0.914 0.994 0.991  0.995 0.994 0.990  0.958   \n",
       "PrecisionOutputNoun         0.670 0.883 0.848  0.918 0.875 0.818  0.753   \n",
       "RecallOutputNoun            0.591 0.878 0.832  0.915 0.872 0.790  0.698   \n",
       "F1ScoreOutputNoun           0.628 0.880 0.840  0.917 0.873 0.804  0.724   \n",
       "PrecisionOutputBoth_Nouns   0.645 0.736 0.707  0.745 0.768 0.569  0.694   \n",
       "RecallOutputBoth_Nouns      0.551 0.733 0.703  0.745 0.766 0.568  0.646   \n",
       "F1ScoreOutputBoth_Nouns     0.594 0.735 0.705  0.745 0.767 0.568  0.669   \n",
       "PrecisionOutputBoth_Verbs   0.594 0.639 0.621  0.648 0.693 0.500  0.655   \n",
       "RecallOutputBoth_Verbs      0.587 0.639 0.617  0.649 0.692 0.500  0.648   \n",
       "F1ScoreOutputBoth_Verbs     0.591 0.639 0.619  0.648 0.692 0.500  0.651   \n",
       "\n",
       "Extractor                 custom2  \n",
       "AccuracyVerbRequired        0.860  \n",
       "F1ScoreVerbRequired         0.918  \n",
       "AccuracyNounRequired        0.961  \n",
       "F1ScoreNounRequired         0.980  \n",
       "PrecisionOutputNoun         0.817  \n",
       "RecallOutputNoun            0.777  \n",
       "F1ScoreOutputNoun           0.797  \n",
       "PrecisionOutputBoth_Nouns   0.750  \n",
       "RecallOutputBoth_Nouns      0.727  \n",
       "F1ScoreOutputBoth_Nouns     0.738  \n",
       "PrecisionOutputBoth_Verbs   0.718  \n",
       "RecallOutputBoth_Verbs      0.707  \n",
       "F1ScoreOutputBoth_Verbs     0.713  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(os.path.join('..', 'datasets', 'activity_dataset_large.csv'), sep=';')\n",
    "result_files = ['corenlp-phrases.csv', 'flair-phrases.csv', 'spacy-phrases.csv', 'stanza-phrases.csv', \n",
    "                'bert-phrases.csv', 'allen-phrases.csv', 'custom-phrases.csv', 'custom2-phrases.csv']\n",
    "result_files = list(map(lambda _: os.path.join('larger', _), result_files))\n",
    "results = pd.DataFrame([calculate_extraction_performance(file, original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].str.replace('larger/', '')\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Extractor</th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>allen</th>\n",
       "      <th>custom</th>\n",
       "      <th>custom2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyVerbRequired</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreVerbRequired</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccuracyNounRequired</th>\n",
       "      <td>0.907</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNounRequired</th>\n",
       "      <td>0.951</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputNoun</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputNoun</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputNoun</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Nouns</th>\n",
       "      <td>0.208</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Nouns</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Nouns</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionOutputBoth_Verbs</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallOutputBoth_Verbs</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreOutputBoth_Verbs</th>\n",
       "      <td>0.399</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Extractor                 corenlp flair spacy stanza  bert allen custom  \\\n",
       "AccuracyVerbRequired        0.520 0.666 0.596  0.509 0.744 0.454  0.754   \n",
       "F1ScoreVerbRequired         0.652 0.781 0.723  0.638 0.840 0.586  0.849   \n",
       "AccuracyNounRequired        0.907 1.000 1.000  1.000 1.000 1.000  0.959   \n",
       "F1ScoreNounRequired         0.951 1.000 1.000  1.000 1.000 1.000  0.979   \n",
       "PrecisionOutputNoun         0.271 0.765 0.747  0.811 0.753 0.732  0.520   \n",
       "RecallOutputNoun            0.232 0.765 0.747  0.811 0.753 0.732  0.466   \n",
       "F1ScoreOutputNoun           0.250 0.765 0.747  0.811 0.753 0.732  0.492   \n",
       "PrecisionOutputBoth_Nouns   0.208 0.484 0.380  0.331 0.558 0.245  0.424   \n",
       "RecallOutputBoth_Nouns      0.190 0.484 0.380  0.331 0.558 0.245  0.409   \n",
       "F1ScoreOutputBoth_Nouns     0.199 0.484 0.380  0.331 0.558 0.245  0.416   \n",
       "PrecisionOutputBoth_Verbs   0.410 0.462 0.380  0.317 0.559 0.250  0.560   \n",
       "RecallOutputBoth_Verbs      0.389 0.462 0.380  0.317 0.559 0.250  0.546   \n",
       "F1ScoreOutputBoth_Verbs     0.399 0.462 0.380  0.317 0.559 0.250  0.553   \n",
       "\n",
       "Extractor                 custom2  \n",
       "AccuracyVerbRequired        0.814  \n",
       "F1ScoreVerbRequired         0.889  \n",
       "AccuracyNounRequired        0.982  \n",
       "F1ScoreNounRequired         0.991  \n",
       "PrecisionOutputNoun         0.566  \n",
       "RecallOutputNoun            0.546  \n",
       "F1ScoreOutputNoun           0.556  \n",
       "PrecisionOutputBoth_Nouns   0.485  \n",
       "RecallOutputBoth_Nouns      0.477  \n",
       "F1ScoreOutputBoth_Nouns     0.481  \n",
       "PrecisionOutputBoth_Verbs   0.644  \n",
       "RecallOutputBoth_Verbs      0.638  \n",
       "F1ScoreOutputBoth_Verbs     0.641  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(os.path.join('..', 'datasets', 'activity_dataset_large_concat.csv'), sep=';')\n",
    "result_files = ['corenlp-phrases-concat.csv', 'flair-phrases-concat.csv', 'spacy-phrases-concat.csv', 'stanza-phrases-concat.csv', \n",
    "                'bert-phrases-concat.csv', 'allen-phrases-concat.csv', 'custom-phrases-concat.csv', 'custom2-phrases-concat.csv']\n",
    "result_files = list(map(lambda _: os.path.join('larger', _), result_files))\n",
    "results = pd.DataFrame([calculate_extraction_performance(file, original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].str.replace('larger/', '')\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Extractor</th>\n",
       "      <th>corenlp</th>\n",
       "      <th>flair</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>bert</th>\n",
       "      <th>allen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AccuracyNEFound</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEFound</th>\n",
       "      <td>0.437</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEEntry</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEEntry</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEEntry</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecisionNEType</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecallNEType</th>\n",
       "      <td>0.278</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1ScoreNEType</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Extractor        corenlp flair spacy stanza  bert allen\n",
       "AccuracyNEFound    0.819 0.816 0.816  0.921 0.733 0.807\n",
       "F1ScoreNEFound     0.437 0.605 0.572  0.811 0.527 0.624\n",
       "PrecisionNEEntry   0.734 0.744 0.766  0.940 0.382 0.756\n",
       "RecallNEEntry      0.233 0.478 0.429  0.727 0.258 0.551\n",
       "F1ScoreNEEntry     0.354 0.582 0.550  0.820 0.308 0.638\n",
       "PrecisionNEType    0.872 0.889 0.893  0.943 0.754 0.890\n",
       "RecallNEType       0.278 0.571 0.504  0.731 0.513 0.653\n",
       "F1ScoreNEType      0.421 0.696 0.645  0.823 0.611 0.754"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_original = pd.read_csv(os.path.join('..', 'datasets', 'ner_dataset_final.csv'), sep=';')\n",
    "result_files = ['corenlp-ner.csv', 'flair-ner.csv', 'spacy-ner.csv', 'stanza-ner.csv', 'bert-ner.csv', 'allen-ner.csv']\n",
    "result_files = list(map(lambda _: os.path.join('smaller', _), result_files))\n",
    "results = pd.DataFrame([calculate_ner_performance(file, ner_original) for file in result_files]).T\n",
    "results.columns = results.loc['Extractor'].str.replace('smaller/', '')\n",
    "results.drop(labels=['Extractor'], axis=0, inplace=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
